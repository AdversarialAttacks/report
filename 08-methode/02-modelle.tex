\subsection{Klassifikationsmodelle} \label{chap:klassifikationsmodelle}
Diese Untersuchung der Universal Adversarial Perturbations bewertete die Generalisierbarkeit verschiedener Klassifikationsmodelle über diverse Architekturen hinweg. Dazu wurden Modelle wie ResNet \cite{he_deep_2015}, DenseNet \cite{huang_densely_2018}, EfficientNetV2 \cite{tan_efficientnetv2_2021} und das Transformer-basierte Modell Vision Transformer \acrshort{vit} \cite{dosovitskiy_image_2021}, bereitgestellt durch die PyTorch Library, verwendet.

In jeder dieser Modellfamilien wurden zwei bis drei Modelle trainiert und evaluiert. Durch die Vielfalt der verwendeten Modelle wird sichergestellt, dass die Ergebnisse nicht auf eine spezifische Architektur beschränkt sind, was verallgemeinerbare Schlussfolgerungen über universelle adversarial Perturbationen ermöglicht.

Modelle, die kein erfolgreiches Training durchliefen, wurden aussortiert und nicht weiter berücksichtigt. Betroffen waren unter anderem die Modellfamilien AlexNet \cite{krizhevsky_imagenet_2012} und VGG \cite{simonyan_very_2015}. Eine ausführlichere Darstellung hierzu findet sich im Kapitel \ref{chap:ergebnisse-modelltraining}: \nameref{chap:ergebnisse-modelltraining}.

Bei der Berechnung der Metriken, der Generation der Perturbationen und der Robustifizierung des Modells, wird in dieser Arbeit jegliches Modell als $f(\cdot)$ referenziert. Wird ein spezifisches Modell referenziert, dann wird dies so getan: $f_{\text{Modell,Datensatz}}(\cdot)$.

\subsubsection{ResNet}
Das ResNet, oder Residual Neural Network, wurde von Kaiming et al. \cite{he_deep_2015} entwickelt und erreichte einen Fehler von 3.57\% auf dem ImageNet-Testdatensatz. Dieses Ergebnis führte zum Sieg in der Klassifikationsaufgabe des ILSVRC 2015. Beim ResNet werden Residual Connections eingesetzt, um sogenannte "`Skip Connections"' zwischen den Schichten des neuronalen Netzwerks zu etablieren. Diese Verbindungen erleichtern den direkten Fluss von Informationen zwischen den Schichten, was das Problem des Vanishing Gradient während des Trainings verhindert.

Durch die Residual Connections können tiefe neuronale Netzwerke effektiver trainiert werden, da sie den Gradientenfluss durch das Netzwerk erleichtern. Dies verbessert oft die Konvergenz und verhindert Gradientenprobleme, die bei sehr tiefen neuronalen Netzwerken auftreten können.

Die Grundidee hinter Residual Connections ist, die ursprüngliche Eingabe eines Blocks mit der Ausgabe desselben Blocks zu addieren. Dadurch entsteht eine Art "`Shortcut"', der es dem Netzwerk ermöglicht, die Identität zu lernen, falls dies für die beste Leistung erforderlich ist. Dieses Konzept hat sich als äusserst effektiv erwiesen und hat die Leistung von tiefen neuronalen Netzwerken erheblich verbessert.

\subsubsection{DenseNet}
Das DenseNet, kurz für Dense Convolutional Network, wurde von Huang et al. \cite{huang_densely_2018} eingeführt und stellt eine Weiterentwicklung der Residual Neural Networks (ResNets) dar. Im Gegensatz zu ResNets, die Residual Connections nutzen, um "`Skip Connections"' zwischen Schichten herzustellen, verbindet DenseNet jede Schicht direkt mit allen nachfolgenden Schichten in einem Feedforward-Muster. Diese dichte Verbindungsstruktur ermöglicht eine effizientere Informationsübertragung zwischen den Schichten und fördert die Wiederverwendung von Merkmalen durch das gesamte Netzwerk.

Durch die direkten Verbindungen zwischen allen Schichten kann DenseNet den Informationsverlust während des Trainings reduzieren und die Stabilität des Gradientenflusses verbessern. Dies führt häufig zu einer besseren Nutzung der verfügbaren Daten und kann die Genauigkeit und Effizienz des Modells erhöhen.

Die grundlegende Idee hinter DenseNet besteht darin, dass jede Schicht nicht nur Ausgaben von vorherigen Schichten empfängt, sondern auch ihre eigenen Ausgaben an alle nachfolgenden Schichten weitergibt. Dieser Ansatz ermöglicht es dem Netzwerk, eine tiefe Hierarchie von Merkmalen zu lernen und dabei die Anzahl der zu optimierenden Parameter zu reduzieren, was zu kompakteren Modellen und besserer Generalisierung führt.

\subsubsection{EfficientNetV2}
EfficientNetV2, vorgestellt von Tan et al. (2021) \cite{tan_efficientnetv2_2021}, ist eine Weiterentwicklung des EfficientNet-Modells. Das Modell zielt darauf ab, ein optimales Gleichgewicht zwischen Modellgrösse und Leistung zu erreichen, indem eine skalierbare Compound Scaling-Strategie angewendet wird.

Im Gegensatz zu früheren Ansätzen, die sich hauptsächlich auf die Tiefe, Breite und Auflösung der Netzwerke konzentrierten, berücksichtigt EfficientNetV2 auch die Netzwerkstruktur. Es verwendet verbesserte Bausteine wie EfficientConv, eine effizientere Variante der Standard-Convolution. Diese Verbesserungen tragen dazu bei, die Leistung und Effizienz des Modells zu steigern.

EfficientNetV2 erreicht mit weniger Parametern vergleichbare oder sogar bessere Leistungen bei verschiedenen Bilderkennungsaufgaben als andere Modelle. Diese Effizienz macht es zu einer attraktiven Wahl für ressourcenbeschränkte Umgebungen oder Anwendungen, bei denen schnelle Inferenzzeiten erforderlich sind.

\subsubsection{ViT}
Der Vision Transformer (\acrshort{vit}), vorgestellt von Dosovitskiy et al. (2021) \cite{dosovitskiy_image_2021}, ist ein kürzlich entwickeltes Modell für die Bildklassifizierung. Anders als traditionelle Convolutional Neural Networks \acrshort{cnn}s nutzt \acrshort{vit} eine transformerbasierte Architektur, die ursprünglich für die Verarbeitung von Sequenzen in natürlicher Sprache entwickelt wurde.

ViT zerlegt das Eingabebild in Patches und behandelt diese als Token einer Sequenz, die dann von einem Transformer-Encoder verarbeitet werden. Diese Patch-Embedding-Technik ermöglicht es \acrshort{vit}, die räumlichen Beziehungen zwischen den Bildpixeln effektiv zu erfassen und sie in einen hochdimensionalen Raum zu projizieren, in dem sie von den Transformer-Blöcken verarbeitet werden.

Durch die Verwendung von Transformer-Architekturen erreicht \acrshort{vit} eine hohe Skalierbarkeit und Flexibilität und kann komplexe Muster in Bildern erfassen, die für herkömmliche \acrshort{cnn}s schwer zu modellieren sind. Dies hat zu beeindruckenden Leistungen auf verschiedenen Bildklassifizierungsaufgaben geführt und das Potenzial von Transformer-Modellen für die visuelle Verarbeitung aufgezeigt.